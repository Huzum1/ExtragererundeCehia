import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
from datetime import datetime
import re

st.set_page_config(page_title="Lottery Data Extractor", page_icon="ğŸ°", layout="wide")

# IniÈ›ializare session state
if 'saved_sources' not in st.session_state:
    st.session_state.saved_sources = []

if 'extracted_data' not in st.session_state:
    st.session_state.extracted_data = None

st.title("ğŸ° Lottery Data Extractor")
st.markdown("Extrage date istorice de la diverse loterii")

# Sidebar pentru surse salvate
with st.sidebar:
    st.header("ğŸ“‹ Surse Salvate")
    
    if st.session_state.saved_sources:
        for idx, source in enumerate(st.session_state.saved_sources):
            with st.expander(f"{source['name']}"):
                st.write(f"**URL:** {source['url']}")
                st.write(f"**Tip:** {source['type']}")
                if st.button(f"È˜terge", key=f"del_{idx}"):
                    st.session_state.saved_sources.pop(idx)
                    st.rerun()
    else:
        st.info("Nicio sursÄƒ salvatÄƒ Ã®ncÄƒ")

# Tab-uri principale
tab1, tab2, tab3 = st.tabs(["â• AdaugÄƒ SursÄƒ", "ğŸ“Š Extrage Date", "â„¹ï¸ Info"])

with tab1:
    st.header("AdaugÄƒ o nouÄƒ sursÄƒ de loterie")
    
    col1, col2 = st.columns(2)
    
    with col1:
        source_name = st.text_input("Nume sursÄƒ", placeholder="ex: Cehia Keno Rapido")
        source_url = st.text_input("URL complet", placeholder="https://...")
        
    with col2:
        source_type = st.selectbox(
            "Tip loterie",
            ["Keno", "Loto", "Powerball", "EuroJackpot", "Rapido", "Altul"]
        )
        
        numbers_count = st.number_input("CÃ¢te numere se extrag", min_value=1, max_value=100, value=20)
    
    numbers_range = st.text_input("Interval numere", placeholder="ex: 1-80 sau 1-66", value="1-80")
    
    # InformaÈ›ii despre selectori CSS/HTML
    with st.expander("âš™ï¸ SetÄƒri Avansate (OpÈ›ional)"):
        st.markdown("AjutÄƒ aplicaÈ›ia sÄƒ gÄƒseascÄƒ datele pe paginÄƒ:")
        css_selector = st.text_input("Selector CSS pentru tabel/rezultate", placeholder="ex: .results-table, #draws")
        date_format = st.text_input("Format datÄƒ", placeholder="ex: DD.MM.YYYY sau YYYY-MM-DD", value="DD.MM.YYYY")
    
    if st.button("ğŸ’¾ SalveazÄƒ Sursa", type="primary"):
        if source_name and source_url:
            new_source = {
                'name': source_name,
                'url': source_url,
                'type': source_type,
                'numbers_count': numbers_count,
                'numbers_range': numbers_range,
                'css_selector': css_selector if css_selector else None,
                'date_format': date_format
            }
            st.session_state.saved_sources.append(new_source)
            st.success(f"âœ… Sursa '{source_name}' a fost salvatÄƒ!")
        else:
            st.error("Te rog completeazÄƒ cel puÈ›in numele È™i URL-ul!")

with tab2:
    st.header("Extrage date de la sursele salvate")
    
    if not st.session_state.saved_sources:
        st.warning("Nu ai surse salvate! AdaugÄƒ o sursÄƒ Ã®n tab-ul 'AdaugÄƒ SursÄƒ'")
    else:
        selected_source = st.selectbox(
            "Alege sursa",
            range(len(st.session_state.saved_sources)),
            format_func=lambda x: st.session_state.saved_sources[x]['name']
        )
        
        source = st.session_state.saved_sources[selected_source]
        
        col1, col2 = st.columns(2)
        with col1:
            num_rounds = st.number_input("CÃ¢te runde sÄƒ extrag", min_value=1, max_value=5000, value=100)
        
        with col2:
            st.write(f"**URL:** {source['url']}")
            st.write(f"**Tip:** {source['type']}")
        
        use_api = st.checkbox("ğŸš€ ÃncearcÄƒ extragere avansatÄƒ (API/Ajax)", value=True, 
                             help="FoloseÈ™te metode alternative pentru a Ã®ncÄƒrca toate datele")
        
        if st.button("ğŸ” Extrage Date", type="primary"):
            with st.spinner(f"Extrag {num_rounds} runde de la {source['name']}..."):
                try:
                    results = []
                    soup = None
                    
                    # Pentru Sazka.cz - folosim API-ul lor direct
                    if 'sazka.cz' in source['url'] and use_api:
                        try:
                            st.info("ğŸ¯ Ãncerc sÄƒ extrag direct din API Sazka...")
                            
                            # Sazka foloseÈ™te un API pentru a Ã®ncÄƒrca datele
                            api_url = "https://www.sazka.cz/api/v1/lottery-draws"
                            
                            headers = {
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                                'Accept': 'application/json',
                                'Referer': source['url']
                            }
                            
                            # DeterminÄƒ ID-ul loteriei din URL
                            lottery_id = None
                            if 'rychle-kacky' in source['url']:
                                lottery_id = 'rychle-kacky'
                            elif 'keno' in source['url']:
                                lottery_id = 'keno'
                            
                            if lottery_id:
                                # ÃncearcÄƒ sÄƒ obÈ›ii datele prin API
                                params = {
                                    'lottery': lottery_id,
                                    'limit': min(num_rounds, 1000),
                                    'offset': 0
                                }
                                
                                response = requests.get(api_url, headers=headers, params=params, timeout=15)
                                
                                if response.status_code == 200:
                                    data = response.json()
                                    st.success(f"âœ… Am gÄƒsit API-ul! Procesez datele...")
                                    
                                    # ProceseazÄƒ datele JSON
                                    if 'draws' in data:
                                        for draw in data['draws'][:num_rounds]:
                                            row = []
                                            # Extrage ID
                                            if 'drawId' in draw:
                                                row.append(str(draw['drawId']))
                                            # Extrage data
                                            if 'drawTime' in draw:
                                                row.append(draw['drawTime'])
                                            # Extrage numerele
                                            if 'numbers' in draw:
                                                numbers = ', '.join(map(str, draw['numbers']))
                                                row.append(numbers)
                                            
                                            if row:
                                                results.append(row)
                                else:
                                    st.warning(f"API status: {response.status_code}, Ã®ncerc metoda standard...")
                        
                        except Exception as e:
                            st.warning(f"Nu am putut folosi API-ul: {str(e)}")
                            st.info("ğŸ“ Ãncerc metoda standard...")
                    
                    # DacÄƒ nu am rezultate din API, foloseÈ™te scraping HTML
                    if not results:
                        headers = {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                            'Accept-Language': 'cs,en;q=0.9',
                            'Referer': 'https://www.sazka.cz/'
                        }
                        
                        response = requests.get(source['url'], headers=headers, timeout=15)
                        response.raise_for_status()
                        soup = BeautifulSoup(response.content, 'html.parser')
    
                    # Extrage datele din HTML (dacÄƒ nu am rezultate din API)
                    if not results and soup:
                        # MetodÄƒ genericÄƒ - cautÄƒ tabele È™i liste
                        tables = soup.find_all('table')
                        
                        if tables:
                            st.info(f"Am gÄƒsit {len(tables)} tabel(e) pe paginÄƒ")
                            
                            # ProceseazÄƒ primul tabel
                            for row in tables[0].find_all('tr')[1:num_rounds+1]:  # Skip header
                                cells = row.find_all(['td', 'th'])
                                if len(cells) >= 2:
                                    row_data = [cell.get_text(strip=True) for cell in cells]
                                    results.append(row_data)
                        
                        # DacÄƒ nu gÄƒsim tabele, cÄƒutÄƒm alte structuri
                        if not results:
                            # CautÄƒ div-uri sau span-uri cu clase comune
                            divs = soup.find_all('div', class_=re.compile(r'result|draw|number|winning|vysledk'))
                            if divs:
                                st.info(f"Am gÄƒsit {len(divs)} elemente cu rezultate")
                                
                                # ÃncearcÄƒ sÄƒ extragÄƒ din div-uri
                                for div in divs[:num_rounds]:
                                    text = div.get_text(strip=True)
                                    if text:
                                        # ÃncearcÄƒ sÄƒ gÄƒseascÄƒ pattern-uri de numere
                                        numbers = re.findall(r'\d+', text)
                                        if len(numbers) >= 5:  # Are sens ca rezultat de loterie
                                            results.append([text])
                    
                    if results:
                        # CreazÄƒ DataFrame
                        df = pd.DataFrame(results)
                        st.session_state.extracted_data = df
                        
                        st.success(f"âœ… Am extras {len(results)} runde!")
                        
                        st.dataframe(df, use_container_width=True)
                        
                        # Download buttons
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            csv = df.to_csv(index=False)
                            st.download_button(
                                "ğŸ“¥ Download CSV",
                                csv,
                                f"{source['name']}_data.csv",
                                "text/csv"
                            )
                        
                        with col2:
                            excel_buffer = pd.ExcelWriter('temp.xlsx', engine='openpyxl')
                            df.to_excel(excel_buffer, index=False)
                            excel_buffer.close()
                            
                        with col3:
                            json_str = df.to_json(orient='records', indent=2)
                            st.download_button(
                                "ğŸ“¥ Download JSON",
                                json_str,
                                f"{source['name']}_data.json",
                                "application/json"
                            )
                    else:
                        st.error("Nu am putut extrage date. Structura paginii ar putea fi diferitÄƒ.")
                        st.info("ğŸ’¡ Sfat: VerificÄƒ URL-ul sau Ã®ncearcÄƒ sÄƒ adaugi un selector CSS Ã®n setÄƒrile avansate")
                        
                        # AratÄƒ preview HTML pentru debugging
                        with st.expander("ğŸ” Vezi structura HTML (pentru debugging)"):
                            st.code(soup.prettify()[:5000], language='html')
                
                except requests.exceptions.RequestException as e:
                    st.error(f"Eroare la accesarea URL-ului: {str(e)}")
                except Exception as e:
                    st.error(f"Eroare: {str(e)}")

with tab3:
    st.header("â„¹ï¸ Cum sÄƒ foloseÈ™ti aplicaÈ›ia")
    
    st.markdown("""
    ### ğŸ“ PaÈ™i:
    
    1. **AdaugÄƒ o sursÄƒ**
       - Mergi la tab-ul "AdaugÄƒ SursÄƒ"
       - CompleteazÄƒ numele loteriei È™i URL-ul complet
       - Alege tipul È™i configureazÄƒ parametrii
       - SalveazÄƒ sursa
    
    2. **Extrage date**
       - Mergi la tab-ul "Extrage Date"
       - Alege sursa din listÄƒ
       - SpecificÄƒ cÃ¢te runde vrei sÄƒ extragi
       - ApasÄƒ "Extrage Date"
    
    3. **Download**
       - DescarcÄƒ datele Ã®n format CSV, Excel sau JSON
    
    ### ğŸ¯ Exemple de surse:
    
    - **Cehia Keno**: https://www.fortunacr.cz/statistiky
    - **Loto RomÃ¢nia**: https://www.loto.ro/rezultate-loto
    - **Euro Jackpot**: https://www.euro-jackpot.net/ro/rezultate
    
    ### âš ï¸ Note importante:
    
    - Unele site-uri pot avea protecÈ›ie anti-scraping
    - Extragerea avansatÄƒ Ã®ncearcÄƒ sÄƒ foloseascÄƒ API-uri pentru date complete
    - Pentru Sazka.cz, aplicaÈ›ia detecteazÄƒ automat API-ul lor
    - DacÄƒ site-ul Ã®ncarcÄƒ date dinamic (cu JavaScript), bifeazÄƒ opÈ›iunea avansatÄƒ
    - Prima Ã®ncÄƒrcare poate fi mai lentÄƒ dar va extrage toate rundele disponibile
    
    ### ğŸ”§ SetÄƒri Avansate:
    
    DacÄƒ aplicaÈ›ia nu gÄƒseÈ™te automat datele:
    - Deschide site-ul Ã®n browser
    - Click dreapta pe tabelul cu rezultate â†’ "Inspect"
    - CautÄƒ class sau id-ul containerului (ex: `.results-table`)
    - AdaugÄƒ acest selector Ã®n setÄƒrile avansate
    """)
    
    st.divider()
    
    st.markdown("""
    ### ğŸ“¦ Instalare pentru GitHub:
    
    CreeazÄƒ fiÈ™ierul `requirements.txt`:
    ```
    streamlit
    requests
    beautifulsoup4
    pandas
    openpyxl
    lxml
    ```
    
    RuleazÄƒ local:
    ```bash
    streamlit run app.py
    ```
    """)

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    ğŸ° Lottery Data Extractor v1.0 | Made with Streamlit
</div>
""", unsafe_allow_html=True)