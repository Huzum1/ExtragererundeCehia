import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
from datetime import datetime
import re

st.set_page_config(page_title="Lottery Data Extractor", page_icon="ğŸ°", layout="wide")

# IniÈ›ializare session state
if 'saved_sources' not in st.session_state:
    st.session_state.saved_sources = []

if 'extracted_data' not in st.session_state:
    st.session_state.extracted_data = None

st.title("ğŸ° Lottery Data Extractor")
st.markdown("Extrage date istorice de la diverse loterii")

# Sidebar pentru surse salvate
with st.sidebar:
    st.header("ğŸ“‹ Surse Salvate")
    
    if st.session_state.saved_sources:
        for idx, source in enumerate(st.session_state.saved_sources):
            with st.expander(f"{source['name']}"):
                st.write(f"**URL:** {source['url']}")
                st.write(f"**Tip:** {source['type']}")
                if st.button(f"È˜terge", key=f"del_{idx}"):
                    st.session_state.saved_sources.pop(idx)
                    st.rerun()
    else:
        st.info("Nicio sursÄƒ salvatÄƒ Ã®ncÄƒ")

# Tab-uri principale
tab1, tab2, tab3 = st.tabs(["â• AdaugÄƒ SursÄƒ", "ğŸ“Š Extrage Date", "â„¹ï¸ Info"])

with tab1:
    st.header("AdaugÄƒ o nouÄƒ sursÄƒ de loterie")
    
    col1, col2 = st.columns(2)
    
    with col1:
        source_name = st.text_input("Nume sursÄƒ", placeholder="ex: Cehia Keno Rapido")
        source_url = st.text_input("URL complet", placeholder="https://...")
        
    with col2:
        source_type = st.selectbox(
            "Tip loterie",
            ["Keno", "Loto", "Powerball", "EuroJackpot", "Rapido", "Altul"]
        )
        
        numbers_count = st.number_input("CÃ¢te numere se extrag", min_value=1, max_value=100, value=20)
    
    numbers_range = st.text_input("Interval numere", placeholder="ex: 1-80 sau 1-66", value="1-80")
    
    # InformaÈ›ii despre selectori CSS/HTML
    with st.expander("âš™ï¸ SetÄƒri Avansate (OpÈ›ional)"):
        st.markdown("AjutÄƒ aplicaÈ›ia sÄƒ gÄƒseascÄƒ datele pe paginÄƒ:")
        css_selector = st.text_input("Selector CSS pentru tabel/rezultate", placeholder="ex: .results-table, #draws")
        date_format = st.text_input("Format datÄƒ", placeholder="ex: DD.MM.YYYY sau YYYY-MM-DD", value="DD.MM.YYYY")
    
    if st.button("ğŸ’¾ SalveazÄƒ Sursa", type="primary"):
        if source_name and source_url:
            new_source = {
                'name': source_name,
                'url': source_url,
                'type': source_type,
                'numbers_count': numbers_count,
                'numbers_range': numbers_range,
                'css_selector': css_selector if css_selector else None,
                'date_format': date_format
            }
            st.session_state.saved_sources.append(new_source)
            st.success(f"âœ… Sursa '{source_name}' a fost salvatÄƒ!")
        else:
            st.error("Te rog completeazÄƒ cel puÈ›in numele È™i URL-ul!")

with tab2:
    st.header("Extrage date de la sursele salvate")
    
    if not st.session_state.saved_sources:
        st.warning("Nu ai surse salvate! AdaugÄƒ o sursÄƒ Ã®n tab-ul 'AdaugÄƒ SursÄƒ'")
    else:
        selected_source = st.selectbox(
            "Alege sursa",
            range(len(st.session_state.saved_sources)),
            format_func=lambda x: st.session_state.saved_sources[x]['name']
        )
        
        source = st.session_state.saved_sources[selected_source]
        
        col1, col2 = st.columns(2)
        with col1:
            num_rounds = st.number_input("CÃ¢te runde sÄƒ extrag", min_value=1, max_value=5000, value=100)
        
        with col2:
            st.write(f"**URL:** {source['url']}")
            st.write(f"**Tip:** {source['type']}")
        
        use_api = st.checkbox("ğŸš€ ÃncearcÄƒ extragere avansatÄƒ (API/Ajax)", value=True, 
                             help="FoloseÈ™te metode alternative pentru a Ã®ncÄƒrca toate datele")
        
        if st.button("ğŸ” Extrage Date", type="primary"):
            with st.spinner(f"Extrag {num_rounds} runde de la {source['name']}..."):
                try:
                    results = []
                    soup = None
                    
                    # ÃncarcÄƒ pagina
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                        'Accept-Language': 'cs,en;q=0.9',
                        'Referer': 'https://www.sazka.cz/'
                    }
                    
                    response = requests.get(source['url'], headers=headers, timeout=15)
                    response.raise_for_status()
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    st.info("ğŸ“„ Am Ã®ncÄƒrcat pagina, analizez structura...")
                    
                    # Pentru Sazka.cz - cÄƒutÄƒm structura specificÄƒ
                    if 'sazka.cz' in source['url']:
                        # CautÄƒ toate elementele care ar putea conÈ›ine rezultate
                        # Varianta 1: Tabele
                        tables = soup.find_all('table')
                        if tables:
                            st.info(f"âœ“ Am gÄƒsit {len(tables)} tabel(e)")
                            for table_idx, table in enumerate(tables):
                                rows = table.find_all('tr')
                                if len(rows) > 5:  # Pare sÄƒ fie un tabel cu date
                                    st.info(f"Procesez tabelul {table_idx + 1} cu {len(rows)} rÃ¢nduri...")
                                    for row in rows[1:min(len(rows), num_rounds+1)]:
                                        cells = row.find_all(['td', 'th'])
                                        if len(cells) >= 2:
                                            row_data = [cell.get_text(strip=True) for cell in cells]
                                            if any(row_data):  # Nu e rÃ¢nd gol
                                                results.append(row_data)
                                    if results:
                                        break
                        
                        # Varianta 2: Div-uri cu clase specifice Sazka
                        if not results:
                            st.info("Caut div-uri cu rezultate...")
                            result_divs = soup.find_all(['div', 'article', 'section'], 
                                                       class_=re.compile(r'result|draw|vysledek|tah|game', re.IGNORECASE))
                            
                            if result_divs:
                                st.info(f"âœ“ Am gÄƒsit {len(result_divs)} elemente posibile")
                                
                                for div in result_divs[:num_rounds]:
                                    # Extrage text È™i numere
                                    text = div.get_text(separator=' ', strip=True)
                                    
                                    # CautÄƒ ID/numÄƒr extragere
                                    draw_id = re.search(r'(\d{7,})', text)
                                    
                                    # CautÄƒ datÄƒ
                                    date_match = re.search(r'(\d{1,2})[.\s]+(\d{1,2})[.\s]+(\d{4})', text)
                                    
                                    # CautÄƒ orÄƒ
                                    time_match = re.search(r'(\d{1,2}):(\d{2})', text)
                                    
                                    # CautÄƒ numerele extrase (grupuri de numere separate prin virgulÄƒ sau spaÈ›iu)
                                    numbers = re.findall(r'\b(\d{1,2})\b', text)
                                    
                                    # FiltreazÄƒ numerele realiste pentru loterie (1-80 pentru Keno)
                                    valid_numbers = [n for n in numbers if 1 <= int(n) <= 80]
                                    
                                    # DacÄƒ avem suficiente numere, e probabil un rezultat valid
                                    if len(valid_numbers) >= 10:
                                        row = []
                                        if draw_id:
                                            row.append(draw_id.group(1))
                                        if date_match:
                                            row.append(f"{date_match.group(1)}.{date_match.group(2)}.{date_match.group(3)}")
                                        if time_match:
                                            row.append(f"{time_match.group(1)}:{time_match.group(2)}")
                                        
                                        # AdaugÄƒ numerele (primele 20 pentru Keno)
                                        row.append(', '.join(valid_numbers[:20]))
                                        
                                        if len(row) >= 2:
                                            results.append(row)
                        
                        # Varianta 3: CautÄƒ Ã®n scripturile JSON embedate
                        if not results and use_api:
                            st.info("Caut date JSON Ã®n paginÄƒ...")
                            scripts = soup.find_all('script', type='application/json')
                            scripts += soup.find_all('script', string=re.compile(r'draws|results|vysledky'))
                            
                            for script in scripts:
                                script_text = script.string if script.string else str(script)
                                
                                # ÃncearcÄƒ sÄƒ gÄƒseascÄƒ JSON
                                try:
                                    # CautÄƒ pattern-uri JSON
                                    json_matches = re.findall(r'\{[^{}]*"draws?"[^{}]*\}', script_text)
                                    for json_str in json_matches:
                                        try:
                                            data = json.loads(json_str)
                                            if 'draws' in data or 'draw' in data:
                                                st.success("âœ“ Am gÄƒsit date JSON!")
                                                # ProceseazÄƒ JSON-ul gÄƒsit
                                                draws = data.get('draws', [data.get('draw', [])])
                                                for draw in draws[:num_rounds]:
                                                    row = []
                                                    if isinstance(draw, dict):
                                                        row.append(str(draw.get('id', draw.get('drawId', ''))))
                                                        row.append(str(draw.get('date', draw.get('drawTime', ''))))
                                                        nums = draw.get('numbers', draw.get('winning_numbers', []))
                                                        if nums:
                                                            row.append(', '.join(map(str, nums)))
                                                        if row and len(row) >= 2:
                                                            results.append(row)
                                        except:
                                            continue
                                except:
                                    continue
                    
                    # MetodÄƒ genericÄƒ pentru alte site-uri
                    else:
    
                                        # MetodÄƒ genericÄƒ pentru alte site-uri

                    else:
                        tables = soup.find_all('table')
                        if tables:
                            st.info(f"Am gÄƒsit {len(tables)} tabel(e) pe paginÄƒ")
                            for row in tables[0].find_all('tr')[1:num_rounds+1]:
                                cells = row.find_all(['td', 'th'])
                                if len(cells) >= 2:
                                    row_data = [cell.get_text(strip=True) for cell in cells]
                                    results.append(row_data)
                    
                    if results:
                        # CreazÄƒ DataFrame
                        df = pd.DataFrame(results)
                        st.session_state.extracted_data = df
                        
                        st.success(f"âœ… Am extras {len(results)} runde!")
                        
                        st.dataframe(df, use_container_width=True)
                        
                        # Download buttons
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            csv = df.to_csv(index=False)
                            st.download_button(
                                "ğŸ“¥ Download CSV",
                                csv,
                                f"{source['name']}_data.csv",
                                "text/csv"
                            )
                        
                        with col2:
                            excel_buffer = pd.ExcelWriter('temp.xlsx', engine='openpyxl')
                            df.to_excel(excel_buffer, index=False)
                            excel_buffer.close()
                            
                        with col3:
                            json_str = df.to_json(orient='records', indent=2)
                            st.download_button(
                                "ğŸ“¥ Download JSON",
                                json_str,
                                f"{source['name']}_data.json",
                                "application/json"
                            )
                    else:
                        st.error("Nu am putut extrage date. Structura paginii ar putea fi diferitÄƒ.")
                        st.info("ğŸ’¡ Sfat: VerificÄƒ URL-ul sau Ã®ncearcÄƒ sÄƒ adaugi un selector CSS Ã®n setÄƒrile avansate")
                        
                        # AratÄƒ preview HTML pentru debugging
                        with st.expander("ğŸ” Vezi structura HTML (pentru debugging)"):
                            st.code(soup.prettify()[:5000], language='html')
                
                except requests.exceptions.RequestException as e:
                    st.error(f"Eroare la accesarea URL-ului: {str(e)}")
                except Exception as e:
                    st.error(f"Eroare: {str(e)}")

with tab3:
    st.header("â„¹ï¸ Cum sÄƒ foloseÈ™ti aplicaÈ›ia")
    
    st.markdown("""
    ### ğŸ“ PaÈ™i:
    
    1. **AdaugÄƒ o sursÄƒ**
       - Mergi la tab-ul "AdaugÄƒ SursÄƒ"
       - CompleteazÄƒ numele loteriei È™i URL-ul complet
       - Alege tipul È™i configureazÄƒ parametrii
       - SalveazÄƒ sursa
    
    2. **Extrage date**
       - Mergi la tab-ul "Extrage Date"
       - Alege sursa din listÄƒ
       - SpecificÄƒ cÃ¢te runde vrei sÄƒ extragi
       - ApasÄƒ "Extrage Date"
    
    3. **Download**
       - DescarcÄƒ datele Ã®n format CSV, Excel sau JSON
    
    ### ğŸ¯ Exemple de surse:
    
    - **Cehia Keno**: https://www.fortunacr.cz/statistiky
    - **Loto RomÃ¢nia**: https://www.loto.ro/rezultate-loto
    - **Euro Jackpot**: https://www.euro-jackpot.net/ro/rezultate
    
    ### âš ï¸ Note importante:
    
    - Unele site-uri pot avea protecÈ›ie anti-scraping
    - Extragerea avansatÄƒ Ã®ncearcÄƒ sÄƒ foloseascÄƒ API-uri pentru date complete
    - Pentru Sazka.cz, aplicaÈ›ia detecteazÄƒ automat API-ul lor
    - DacÄƒ site-ul Ã®ncarcÄƒ date dinamic (cu JavaScript), bifeazÄƒ opÈ›iunea avansatÄƒ
    - Prima Ã®ncÄƒrcare poate fi mai lentÄƒ dar va extrage toate rundele disponibile
    
    ### ğŸ”§ SetÄƒri Avansate:
    
    DacÄƒ aplicaÈ›ia nu gÄƒseÈ™te automat datele:
    - Deschide site-ul Ã®n browser
    - Click dreapta pe tabelul cu rezultate â†’ "Inspect"
    - CautÄƒ class sau id-ul containerului (ex: `.results-table`)
    - AdaugÄƒ acest selector Ã®n setÄƒrile avansate
    """)
    
    st.divider()
    
    st.markdown("""
    ### ğŸ“¦ Instalare pentru GitHub:
    
    CreeazÄƒ fiÈ™ierul `requirements.txt`:
    ```
    streamlit
    requests
    beautifulsoup4
    pandas
    openpyxl
    lxml
    ```
    
    RuleazÄƒ local:
    ```bash
    streamlit run app.py
    ```
    """)

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    ğŸ° Lottery Data Extractor v1.0 | Made with Streamlit
</div>
""", unsafe_allow_html=True)