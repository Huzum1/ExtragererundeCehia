import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
from datetime import datetime
import re

st.set_page_config(page_title="Lottery Data Extractor", page_icon="ğŸ°", layout="wide")

# IniÈ›ializare session state
if 'saved_sources' not in st.session_state:
    st.session_state.saved_sources = []

if 'extracted_data' not in st.session_state:
    st.session_state.extracted_data = None

st.title("ğŸ° Lottery Data Extractor")
st.markdown("Extrage date istorice de la diverse loterii")

# Sidebar pentru surse salvate
with st.sidebar:
    st.header("ğŸ“‹ Surse Salvate")
    
    if st.session_state.saved_sources:
        for idx, source in enumerate(st.session_state.saved_sources):
            with st.expander(f"{source['name']}"):
                st.write(f"**URL:** {source['url']}")
                st.write(f"**Tip:** {source['type']}")
                if st.button(f"È˜terge", key=f"del_{idx}"):
                    st.session_state.saved_sources.pop(idx)
                    st.rerun()
    else:
        st.info("Nicio sursÄƒ salvatÄƒ Ã®ncÄƒ")

# Tab-uri principale
tab1, tab2, tab3 = st.tabs(["â• AdaugÄƒ SursÄƒ", "ğŸ“Š Extrage Date", "â„¹ï¸ Info"])

with tab1:
    st.header("AdaugÄƒ o nouÄƒ sursÄƒ de loterie")
    
    col1, col2 = st.columns(2)
    
    with col1:
        source_name = st.text_input("Nume sursÄƒ", placeholder="ex: Cehia Keno Rapido")
        source_url = st.text_input("URL complet", placeholder="https://...")
        
    with col2:
        source_type = st.selectbox(
            "Tip loterie",
            ["Keno", "Loto", "Powerball", "EuroJackpot", "Rapido", "Altul"]
        )
        
        numbers_count = st.number_input("CÃ¢te numere se extrag", min_value=1, max_value=100, value=20)
    
    numbers_range = st.text_input("Interval numere", placeholder="ex: 1-80 sau 1-66", value="1-80")
    
    # InformaÈ›ii despre selectori CSS/HTML
    with st.expander("âš™ï¸ SetÄƒri Avansate (OpÈ›ional)"):
        st.markdown("AjutÄƒ aplicaÈ›ia sÄƒ gÄƒseascÄƒ datele pe paginÄƒ:")
        css_selector = st.text_input("Selector CSS pentru tabel/rezultate", placeholder="ex: .results-table, #draws")
        date_format = st.text_input("Format datÄƒ", placeholder="ex: DD.MM.YYYY sau YYYY-MM-DD", value="DD.MM.YYYY")
    
    if st.button("ğŸ’¾ SalveazÄƒ Sursa", type="primary"):
        if source_name and source_url:
            new_source = {
                'name': source_name,
                'url': source_url,
                'type': source_type,
                'numbers_count': numbers_count,
                'numbers_range': numbers_range,
                'css_selector': css_selector if css_selector else None,
                'date_format': date_format
            }
            st.session_state.saved_sources.append(new_source)
            st.success(f"âœ… Sursa '{source_name}' a fost salvatÄƒ!")
        else:
            st.error("Te rog completeazÄƒ cel puÈ›in numele È™i URL-ul!")

with tab2:
    st.header("Extrage date de la sursele salvate")
    
    if not st.session_state.saved_sources:
        st.warning("Nu ai surse salvate! AdaugÄƒ o sursÄƒ Ã®n tab-ul 'AdaugÄƒ SursÄƒ'")
    else:
        selected_source = st.selectbox(
            "Alege sursa",
            range(len(st.session_state.saved_sources)),
            format_func=lambda x: st.session_state.saved_sources[x]['name']
        )
        
        source = st.session_state.saved_sources[selected_source]
        
        col1, col2 = st.columns(2)
        with col1:
            num_rounds = st.number_input("CÃ¢te runde sÄƒ extrag", min_value=1, max_value=5000, value=100)
        
        with col2:
            st.write(f"**URL:** {source['url']}")
            st.write(f"**Tip:** {source['type']}")
        
        use_selenium = st.checkbox("ğŸ¤– FoloseÈ™te browser automat (pentru site-uri dinamice)", value=False)
        
        if st.button("ğŸ” Extrage Date", type="primary"):
            with st.spinner(f"Extrag {num_rounds} runde de la {source['name']}..."):
                try:
                    results = []
                    
                    if use_selenium:
                        # FoloseÈ™te Selenium pentru site-uri cu butoane "Load More"
                        try:
                            from selenium import webdriver
                            from selenium.webdriver.common.by import By
                            from selenium.webdriver.support.ui import WebDriverWait
                            from selenium.webdriver.support import expected_conditions as EC
                            from selenium.webdriver.chrome.options import Options
                            import time
                            
                            st.info("ğŸ¤– Pornesc browser-ul automat...")
                            
                            # Configurare Chrome headless
                            chrome_options = Options()
                            chrome_options.add_argument('--headless')
                            chrome_options.add_argument('--no-sandbox')
                            chrome_options.add_argument('--disable-dev-shm-usage')
                            chrome_options.add_argument('--disable-gpu')
                            chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
                            
                            driver = webdriver.Chrome(options=chrome_options)
                            driver.get(source['url'])
                            
                            # AÈ™teaptÄƒ Ã®ncÄƒrcarea paginii
                            time.sleep(3)
                            
                            # ApasÄƒ butonul "ÃncarcÄƒ mai multe" pÃ¢nÄƒ obÈ›inem destule rezultate
                            click_count = 0
                            max_clicks = (num_rounds // 20) + 2  # Estimare cÃ¢te clickuri sunt necesare
                            
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            for i in range(max_clicks):
                                try:
                                    # CautÄƒ butonul cu diverse variante de text
                                    button_selectors = [
                                        "//button[contains(text(), 'NAÄŒÃST DALÅ Ã')]",
                                        "//button[contains(text(), 'Load more')]",
                                        "//button[contains(text(), 'ÃncarcÄƒ mai multe')]",
                                        "//a[contains(text(), 'NAÄŒÃST DALÅ Ã')]",
                                        "//button[contains(@class, 'load-more')]"
                                    ]
                                    
                                    button_found = False
                                    for selector in button_selectors:
                                        try:
                                            button = WebDriverWait(driver, 5).until(
                                                EC.element_to_be_clickable((By.XPATH, selector))
                                            )
                                            
                                            # Scroll la buton
                                            driver.execute_script("arguments[0].scrollIntoView(true);", button)
                                            time.sleep(1)
                                            
                                            # Click
                                            button.click()
                                            click_count += 1
                                            button_found = True
                                            
                                            status_text.text(f"ğŸ“¥ Click #{click_count} - AÈ™tept Ã®ncÄƒrcarea...")
                                            progress_bar.progress(min((i + 1) / max_clicks, 1.0))
                                            
                                            # AÈ™teaptÄƒ Ã®ncÄƒrcarea datelor noi
                                            time.sleep(2)
                                            break
                                        except:
                                            continue
                                    
                                    if not button_found:
                                        status_text.text("âœ… Nu mai sunt date de Ã®ncÄƒrcat")
                                        break
                                        
                                except Exception as e:
                                    status_text.text(f"â„¹ï¸ Am terminat de Ã®ncÄƒrcat date (Click #{click_count})")
                                    break
                            
                            progress_bar.empty()
                            status_text.empty()
                            
                            # Extrage datele finale
                            soup = BeautifulSoup(driver.page_source, 'html.parser')
                            driver.quit()
                            
                            st.success(f"âœ… Am dat {click_count} click-uri pe buton!")
                            
                        except ImportError:
                            st.error("âŒ Selenium nu este instalat! InstaleazÄƒ: pip install selenium")
                            st.info("ğŸ“ Ãncerc cu metoda standard (fÄƒrÄƒ click automat)...")
                            use_selenium = False
                    
                    if not use_selenium:
                        # MetodÄƒ standard - doar prima paginÄƒ
                        headers = {
                            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                        }
                        
                        response = requests.get(source['url'], headers=headers, timeout=10)
                        response.raise_for_status()
                        soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # Extrage datele din HTML
                    # MetodÄƒ genericÄƒ - cautÄƒ tabele È™i liste
                    tables = soup.find_all('table')
                    
                    if tables:
                        st.info(f"Am gÄƒsit {len(tables)} tabel(e) pe paginÄƒ")
                        
                        # ProceseazÄƒ primul tabel
                        for row in tables[0].find_all('tr')[1:num_rounds+1]:  # Skip header
                            cells = row.find_all(['td', 'th'])
                            if len(cells) >= 2:
                                row_data = [cell.get_text(strip=True) for cell in cells]
                                results.append(row_data)
                    
                    # DacÄƒ nu gÄƒsim tabele, cÄƒutÄƒm alte structuri
                    if not results:
                        # CautÄƒ div-uri sau span-uri cu clase comune
                        divs = soup.find_all('div', class_=re.compile(r'result|draw|number|winning'))
                        if divs:
                            st.info(f"Am gÄƒsit {len(divs)} elemente cu rezultate")
                    
                    if results:
                        # CreazÄƒ DataFrame
                        df = pd.DataFrame(results)
                        st.session_state.extracted_data = df
                        
                        st.success(f"âœ… Am extras {len(results)} runde!")
                        
                        st.dataframe(df, use_container_width=True)
                        
                        # Download buttons
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            csv = df.to_csv(index=False)
                            st.download_button(
                                "ğŸ“¥ Download CSV",
                                csv,
                                f"{source['name']}_data.csv",
                                "text/csv"
                            )
                        
                        with col2:
                            excel_buffer = pd.ExcelWriter('temp.xlsx', engine='openpyxl')
                            df.to_excel(excel_buffer, index=False)
                            excel_buffer.close()
                            
                        with col3:
                            json_str = df.to_json(orient='records', indent=2)
                            st.download_button(
                                "ğŸ“¥ Download JSON",
                                json_str,
                                f"{source['name']}_data.json",
                                "application/json"
                            )
                    else:
                        st.error("Nu am putut extrage date. Structura paginii ar putea fi diferitÄƒ.")
                        st.info("ğŸ’¡ Sfat: VerificÄƒ URL-ul sau Ã®ncearcÄƒ sÄƒ adaugi un selector CSS Ã®n setÄƒrile avansate")
                        
                        # AratÄƒ preview HTML pentru debugging
                        with st.expander("ğŸ” Vezi structura HTML (pentru debugging)"):
                            st.code(soup.prettify()[:5000], language='html')
                
                except requests.exceptions.RequestException as e:
                    st.error(f"Eroare la accesarea URL-ului: {str(e)}")
                except Exception as e:
                    st.error(f"Eroare: {str(e)}")

with tab3:
    st.header("â„¹ï¸ Cum sÄƒ foloseÈ™ti aplicaÈ›ia")
    
    st.markdown("""
    ### ğŸ“ PaÈ™i:
    
    1. **AdaugÄƒ o sursÄƒ**
       - Mergi la tab-ul "AdaugÄƒ SursÄƒ"
       - CompleteazÄƒ numele loteriei È™i URL-ul complet
       - Alege tipul È™i configureazÄƒ parametrii
       - SalveazÄƒ sursa
    
    2. **Extrage date**
       - Mergi la tab-ul "Extrage Date"
       - Alege sursa din listÄƒ
       - SpecificÄƒ cÃ¢te runde vrei sÄƒ extragi
       - ApasÄƒ "Extrage Date"
    
    3. **Download**
       - DescarcÄƒ datele Ã®n format CSV, Excel sau JSON
    
    ### ğŸ¯ Exemple de surse:
    
    - **Cehia Keno**: https://www.fortunacr.cz/statistiky
    - **Loto RomÃ¢nia**: https://www.loto.ro/rezultate-loto
    - **Euro Jackpot**: https://www.euro-jackpot.net/ro/rezultate
    
    ### âš ï¸ Note:
    
    - Unele site-uri pot avea protecÈ›ie anti-scraping
    - Structura HTML diferÄƒ de la site la site
    - Pentru rezultate optime, verificÄƒ cÄƒ URL-ul afiÈ™eazÄƒ rezultatele direct
    - FoloseÈ™te setÄƒrile avansate pentru site-uri complexe
    
    ### ğŸ”§ SetÄƒri Avansate:
    
    DacÄƒ aplicaÈ›ia nu gÄƒseÈ™te automat datele:
    - Deschide site-ul Ã®n browser
    - Click dreapta pe tabelul cu rezultate â†’ "Inspect"
    - CautÄƒ class sau id-ul containerului (ex: `.results-table`)
    - AdaugÄƒ acest selector Ã®n setÄƒrile avansate
    """)
    
    st.divider()
    
    st.markdown("""
    ### ğŸ“¦ Instalare pentru GitHub:
    
    CreeazÄƒ fiÈ™ierul `requirements.txt`:
    ```
    streamlit
    requests
    beautifulsoup4
    pandas
    openpyxl
    lxml
    selenium
    webdriver-manager
    ```
    
    **Pentru Selenium (click automat pe butoane):**
    ```bash
    # InstaleazÄƒ Chrome Driver automat
    pip install webdriver-manager
    ```
    
    RuleazÄƒ local:
    ```bash
    streamlit run app.py
    ```
    """)

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    ğŸ° Lottery Data Extractor v1.0 | Made with Streamlit
</div>
""", unsafe_allow_html=True)
